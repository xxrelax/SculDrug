{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试通过：两种方法的结果在集合意义上等价。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_cluster import radius_graph\n",
    "\n",
    "\n",
    "def remove_subset_edges(main_edge_index, subset_edge_index):\n",
    "# 将边对转换为集合进行操作\n",
    "    main_edges = set(map(tuple, main_edge_index.t().tolist()))\n",
    "    subset_edges = set(map(tuple, subset_edge_index.t().tolist()))\n",
    "\n",
    "    # 从 main_edges 中移除 subset_edges\n",
    "    filtered_edges = main_edges - subset_edges\n",
    "\n",
    "    # 转换回 tensor 格式\n",
    "    filtered_edge_index = torch.tensor(list(filtered_edges), dtype=torch.long, device=main_edge_index.device).t()\n",
    "    return filtered_edge_index\n",
    "def multi_radius_graph(x, batch, radii):\n",
    "    \"\"\"\n",
    "    根据多个半径阈值从节点坐标和批次信息中生成多级别的边集合。\n",
    "    只调用一次 radius_graph，然后根据距离进行分级筛选。\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): 节点坐标, [N, D]\n",
    "        batch (LongTensor): 节点的批次信息, [N]\n",
    "        radii (list or tuple): 递增顺序的半径列表 (例如 [1.35, 1.7, 2.5])\n",
    "\n",
    "    Returns:\n",
    "        edges_list (list of Tensors): 对应 radii 阈值范围划分的边集列表\n",
    "    \"\"\"\n",
    "\n",
    "    # 确保 radii 已经排序\n",
    "    radii = sorted(radii)\n",
    "    r_max = radii[-1]\n",
    "\n",
    "    # 使用最大半径一次性构建边\n",
    "    edge_index_full = radius_graph(x, r=r_max, batch=batch, flow='source_to_target')\n",
    "\n",
    "    # 计算每条边的距离\n",
    "    row, col = edge_index_full\n",
    "    # 假设 x 为 (N, D)\n",
    "    # 计算欧式距离的平方（避免调用 sqrt 提高性能）\n",
    "    diff = x[row] - x[col]\n",
    "    dist_sq = (diff * diff).sum(dim=-1)  # dist^2\n",
    "\n",
    "    # 将半径也转为平方方便比较\n",
    "    radii_sq = [r*r for r in radii]\n",
    "\n",
    "    edges_list = []\n",
    "    # 上一个半径区间的上界\n",
    "    prev_r_sq = 0.0  \n",
    "    for r_sq in radii_sq:\n",
    "        # 选取 dist_sq 在 (prev_r_sq, r_sq] 区间内的边\n",
    "        # 如果希望第一个区间包括从0到r1的所有边，那么 prev_r_sq可设0\n",
    "        mask = (dist_sq <= r_sq) & (dist_sq > prev_r_sq)\n",
    "        edges_list.append(edge_index_full[:, mask])\n",
    "        prev_r_sq = r_sq\n",
    "\n",
    "    return edges_list\n",
    "\n",
    "def normalize_edges(edges):\n",
    "    edges = edges.clone()\n",
    "    # 确保每条边(i,j)中 i<j\n",
    "    sorted_edges = torch.sort(edges, dim=0)[0]\n",
    "    # (2,E) -> (E,2)\n",
    "    sorted_edges = sorted_edges.t()\n",
    "    arr = sorted_edges.cpu().numpy()\n",
    "    # 使用numpy lexsort进行双列排序\n",
    "    idx = np.lexsort((arr[:,1], arr[:,0]))\n",
    "    arr = arr[idx]\n",
    "    return torch.from_numpy(arr).to(edges.device)\n",
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # 模拟数据\n",
    "    N = 50\n",
    "    x = torch.randn(N, 3)\n",
    "    batch = torch.randint(0, 3, (N,))  # 3个batch\n",
    "    radii = [1.35, 1.7, 2.5]\n",
    "\n",
    "    # 方法一：multi_radius_graph\n",
    "    edge_index_levels_multi = multi_radius_graph(x, batch, radii)\n",
    "    edge_index_2p7_multi, edge_index_3p4_multi, edge_index_4p9_multi = edge_index_levels_multi\n",
    "\n",
    "    # 方法二：多次 radius_graph + remove_subset_edges\n",
    "    edge_index_2p7 = radius_graph(x, r=1.35, batch=batch, flow='source_to_target')\n",
    "    edge_index_3p4 = radius_graph(x, r=1.7, batch=batch, flow='source_to_target')\n",
    "    edge_index_4p9 = radius_graph(x, r=2.5, batch=batch, flow='source_to_target')\n",
    "    edge_index_4p9 = remove_subset_edges(edge_index_4p9, edge_index_3p4)\n",
    "    edge_index_3p4 = remove_subset_edges(edge_index_3p4, edge_index_2p7)\n",
    "\n",
    "    # 标准化\n",
    "    norm_2p7_multi = normalize_edges(edge_index_2p7_multi)\n",
    "    norm_2p7 = normalize_edges(edge_index_2p7)\n",
    "    norm_3p4_multi = normalize_edges(edge_index_3p4_multi)\n",
    "    norm_3p4 = normalize_edges(edge_index_3p4)\n",
    "    norm_4p9_multi = normalize_edges(edge_index_4p9_multi)\n",
    "    norm_4p9 = normalize_edges(edge_index_4p9)\n",
    "\n",
    "    # 检查两种方法输出是否在集合意义上一致\n",
    "    eq_2p7 = torch.equal(norm_2p7_multi, norm_2p7)\n",
    "    eq_3p4 = torch.equal(norm_3p4_multi, norm_3p4)\n",
    "    eq_4p9 = torch.equal(norm_4p9_multi, norm_4p9)\n",
    "\n",
    "    if eq_2p7 and eq_3p4 and eq_4p9:\n",
    "        print(\"测试通过：两种方法的结果在集合意义上等价。\")\n",
    "    else:\n",
    "        print(\"测试失败：存在边集合不一致的情况。\")\n",
    "        if not eq_2p7:\n",
    "            print(\"半径1.35对应的边集不一致\")\n",
    "            print(\"multi:\\n\", norm_2p7_multi)\n",
    "            print(\"独立构图:\\n\", norm_2p7)\n",
    "        if not eq_3p4:\n",
    "            print(\"1.35~1.7对应的边集不一致\")\n",
    "            print(\"multi:\\n\", norm_3p4_multi)\n",
    "            print(\"独立构图+去重:\\n\", norm_3p4)\n",
    "        if not eq_4p9:\n",
    "            print(\"1.7~2.5对应的边集不一致\")\n",
    "            print(\"multi:\\n\", norm_4p9_multi)\n",
    "            print(\"独立构图+去重:\\n\", norm_4p9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试通过：两种实现结果在集合意义上相同。\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "def connect_within_batch(x, virtual_mask, batch, mask_ligand):\n",
    "    \"\"\"\n",
    "    建立同一批次中分子与分子、虚拟原子与虚拟原子、分子与虚拟原子之间的连接。\n",
    "    \"\"\"\n",
    "\n",
    "    device = x.device\n",
    "    non_protein_mask = virtual_mask | mask_ligand\n",
    "    non_protein_indices = torch.where(non_protein_mask)[0]\n",
    "    unique_batches = batch[non_protein_indices].unique()\n",
    "    edge_index = []\n",
    "    for b in unique_batches:\n",
    "        nodes_in_batch = non_protein_indices[batch[non_protein_indices] == b]\n",
    "        if nodes_in_batch.size(0) > 1:\n",
    "            edges = torch.combinations(nodes_in_batch, r=2)\n",
    "            edge_index.append(edges)\n",
    "            edge_index.append(edges.flip(dims=[1]))\n",
    "    edge_index = torch.cat(edge_index, dim=0).t().to(device)\n",
    "    return edge_index\n",
    "def connect_within_batch_optimized(x, virtual_mask, batch, mask_ligand):\n",
    "    \"\"\"\n",
    "    优化后的函数：建立同一批次中分子与分子、虚拟原子与虚拟原子、分子与虚拟原子之间的连接。\n",
    "    \n",
    "    所有计算均在 GPU (CUDA) 上进行。\n",
    "    \n",
    "    Args:\n",
    "        x: 输入特征张量 (在 GPU 上)\n",
    "        virtual_mask: 虚拟原子的掩码 (在 GPU 上)\n",
    "        batch: 批次索引，用于区分不同批次的原子 (N_protein,) (在 GPU 上)\n",
    "        mask_ligand: 配体掩码，用于区分配体原子 (在 GPU 上)\n",
    "    \n",
    "    Returns:\n",
    "        edge_index: 边索引张量，形状为 (2, E)，在 GPU 上\n",
    "    \"\"\"\n",
    "    device = x.device\n",
    "    # 确保所有输入张量都在 GPU 上\n",
    "    # 假设在函数外部已经保证 x, virtual_mask, batch, mask_ligand 均在 GPU 上\n",
    "    # 如果不确定，可使用以下语句（根据需要取消注释）：\n",
    "    # virtual_mask = virtual_mask.to(device)\n",
    "    # mask_ligand = mask_ligand.to(device)\n",
    "    # batch = batch.to(device)\n",
    "    \n",
    "    non_protein_mask = virtual_mask | mask_ligand\n",
    "    non_protein_indices = torch.where(non_protein_mask)[0]  # 位于 GPU 上\n",
    "    \n",
    "    # 如果非蛋白原子数量小于等于1，则无需建立边\n",
    "    if non_protein_indices.size(0) <= 1:\n",
    "        return torch.empty((2, 0), dtype=torch.long, device=device)\n",
    "    \n",
    "    batch_non_protein = batch[non_protein_indices]  # 在 GPU 上\n",
    "    N = batch_non_protein.size(0)\n",
    "    \n",
    "    # 在 GPU 上生成所有上三角（不含对角线）的索引对\n",
    "    idx_i, idx_j = torch.triu_indices(N, N, offset=1, device=device)  # 直接在 GPU 上生成\n",
    "    # 筛选出同一批次内的原子对\n",
    "    same_batch_mask = (batch_non_protein[idx_i] == batch_non_protein[idx_j])\n",
    "    \n",
    "    # 获取符合条件的原子索引对\n",
    "    selected_idx_i = idx_i[same_batch_mask]\n",
    "    selected_idx_j = idx_j[same_batch_mask]\n",
    "    \n",
    "    edges = torch.stack([\n",
    "        non_protein_indices[selected_idx_i], \n",
    "        non_protein_indices[selected_idx_j]\n",
    "    ], dim=0)\n",
    "    \n",
    "    # 生成双向边\n",
    "    edges = torch.cat([edges, edges.flip(dims=[0])], dim=1)\n",
    "    return edges\n",
    "\n",
    "def normalize_edges(edges):\n",
    "    # edges 形状为 (2, E) 或 (E, 2)\n",
    "    # 确保 edges 是 (E,2)\n",
    "    if edges.size(0) == 2:\n",
    "        edges = edges.t()\n",
    "\n",
    "    # 对每条边内排序，使 (i, j) 满足 i <= j\n",
    "    sorted_edges = torch.sort(edges, dim=1)[0]\n",
    "\n",
    "    # 转换到 CPU，使用 numpy 进行多列排序\n",
    "    arr = sorted_edges.cpu().numpy()\n",
    "    # 使用 np.lexsort：np.lexsort((keys...)) 按最后一个 key 先排序\n",
    "    # 我们想按第一列再第二列排序，所以 keys 的顺序需要是 (第二列, 第一列)\n",
    "    idx = np.lexsort((arr[:,1], arr[:,0]))\n",
    "\n",
    "    arr = arr[idx]\n",
    "    sorted_edges = torch.from_numpy(arr).to(edges.device)\n",
    "\n",
    "    return sorted_edges\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(42)\n",
    "    device = 'cpu'\n",
    "\n",
    "    # 模拟数据\n",
    "    N = 10\n",
    "    x = torch.randn(N, 3, device=device)              # 节点特征\n",
    "    batch = torch.tensor([0,0,0,0,1,1,1,2,2,2], device=device)  # batch索引\n",
    "    virtual_mask = torch.zeros(N, dtype=torch.bool, device=device)\n",
    "    mask_ligand = torch.zeros(N, dtype=torch.bool, device=device)\n",
    "\n",
    "    # 随机指定一些原子为virtual和ligand以测试功能\n",
    "    virtual_mask[2] = True\n",
    "    virtual_mask[5] = True\n",
    "    mask_ligand[6] = True\n",
    "    mask_ligand[8] = True\n",
    "\n",
    "    # 调用两个函数\n",
    "    edge_orig = connect_within_batch(x, virtual_mask, batch, mask_ligand)\n",
    "    edge_opt = connect_within_batch_optimized(x, virtual_mask, batch, mask_ligand)\n",
    "\n",
    "    # 标准化\n",
    "    norm_orig = normalize_edges(edge_orig)\n",
    "    norm_opt = normalize_edges(edge_opt)\n",
    "\n",
    "    # 检查无序条件下是否相同\n",
    "    if torch.equal(norm_orig, norm_opt):\n",
    "        print(\"测试通过：两种实现结果在集合意义上相同。\")\n",
    "    else:\n",
    "        print(\"测试失败：两种实现结果存在差异。\")\n",
    "        print(\"原始结果：\\n\", norm_orig)\n",
    "        print(\"优化结果：\\n\", norm_opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试失败：两种实现结果存在差异。\n",
      "原始结果： tensor([[ 1.9269e+00,  1.4873e+00,  9.0072e-01, -2.1055e+00,  6.7842e-01],\n",
      "        [-1.2345e+00, -4.3067e-02, -1.6047e+00, -7.5214e-01,  1.6487e+00],\n",
      "        [ 3.4619e-01,  7.2211e-01, -3.5197e-01, -1.4288e+00,  1.1636e+00],\n",
      "        [ 6.3276e-01,  4.1151e+00, -8.8044e-01, -4.5107e-01, -3.8814e-01],\n",
      "        [-7.5813e-01,  1.0783e+00,  8.0080e-01,  1.6806e+00,  1.2791e+00],\n",
      "        [ 2.1571e-03,  1.3603e+00,  3.2060e-01,  5.9161e-01,  8.5936e-01],\n",
      "        [-2.5158e-01,  8.5986e-01, -1.3847e+00, -8.7124e-01, -2.2337e-01],\n",
      "        [ 1.9780e+00,  4.4240e-01, -9.3316e-01,  3.0874e-01, -3.7001e-01],\n",
      "        [-1.5576e+00,  9.9564e-01, -8.7979e-01, -6.0114e-01, -1.2742e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.8024e-02,  5.2581e-01, -4.8799e-01,  1.1914e+00, -8.1401e-01],\n",
      "        [-7.3599e-01, -1.4032e+00,  3.6004e-02, -6.3477e-02,  6.7561e-01],\n",
      "        [-9.7807e-02,  1.8446e+00, -1.1845e+00,  1.3835e+00,  1.4451e+00],\n",
      "        [ 8.5641e-01,  2.2181e+00,  5.2317e-01,  3.4665e-01, -1.9733e-01],\n",
      "        [-1.0546e+00,  1.2780e+00, -1.7219e-01,  5.2379e-01,  5.6622e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0868e-02, -3.3874e-01, -1.3407e+00, -5.8537e-01,  6.4076e-01],\n",
      "        [ 5.8325e-01,  1.0669e+00, -4.5015e-01, -6.7875e-01,  5.7432e-01],\n",
      "        [ 1.8775e-01, -3.5762e-01,  2.6491e-01,  1.2732e+00, -1.3109e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "优化结果： tensor([[ 1.9269e+00,  1.4873e+00,  9.0072e-01, -2.1055e+00,  6.7842e-01],\n",
      "        [-1.2345e+00, -4.3067e-02, -1.6047e+00, -7.5214e-01,  1.6487e+00],\n",
      "        [ 3.4619e-01,  7.2211e-01, -3.5197e-01, -1.4288e+00,  1.1636e+00],\n",
      "        [ 7.6245e-01,  1.6423e+00, -1.5960e-01, -4.9740e-01,  4.3959e-01],\n",
      "        [-7.5813e-01,  1.0783e+00,  8.0080e-01,  1.6806e+00,  1.2791e+00],\n",
      "        [ 2.1571e-03,  1.3603e+00,  3.2060e-01,  5.9161e-01,  8.5936e-01],\n",
      "        [-2.5158e-01,  8.5986e-01, -1.3847e+00, -8.7124e-01, -2.2337e-01],\n",
      "        [ 1.7174e+00,  3.1888e-01, -4.2452e-01,  3.0572e-01, -7.7459e-01],\n",
      "        [-1.5576e+00,  9.9564e-01, -8.7979e-01, -6.0114e-01, -1.2742e+00],\n",
      "        [-3.0595e-02,  7.2479e-01, -8.9633e-01, -3.8889e-01, -7.5737e-01],\n",
      "        [ 7.8024e-02,  5.2581e-01, -4.8799e-01,  1.1914e+00, -8.1401e-01],\n",
      "        [-7.3599e-01, -1.4032e+00,  3.6004e-02, -6.3477e-02,  6.7561e-01],\n",
      "        [-9.7807e-02,  1.8446e+00, -1.1845e+00,  1.3835e+00,  1.4451e+00],\n",
      "        [ 8.5641e-01,  2.2181e+00,  5.2317e-01,  3.4665e-01, -1.9733e-01],\n",
      "        [-1.0546e+00,  1.2780e+00, -1.7219e-01,  5.2379e-01,  5.6622e-02],\n",
      "        [-9.9088e-02,  1.7480e+00,  1.7549e-01,  4.3522e-01, -7.0355e-02],\n",
      "        [ 1.0868e-02, -3.3874e-01, -1.3407e+00, -5.8537e-01,  6.4076e-01],\n",
      "        [ 5.8325e-01,  1.0669e+00, -4.5015e-01, -6.7875e-01,  5.7432e-01],\n",
      "        [ 1.8775e-01, -3.5762e-01,  2.6491e-01,  1.2732e+00, -1.3109e-03],\n",
      "        [ 2.6062e-01,  1.2352e-01, -5.0864e-01,  3.0150e-03,  4.0459e-01]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_scatter\n",
    "\n",
    "class ProteinAggregator:\n",
    "    def aggregate_to_virtual_center_by_batch(self, h_protein, group_indices, virtual_mask, batch):\n",
    "        # 原始版本函数\n",
    "        updated_h_protein = h_protein.clone()\n",
    "        unique_batches = torch.unique(batch)\n",
    "        for b in unique_batches:\n",
    "            batch_mask = (batch == b)\n",
    "            batch_group_indices = group_indices[batch_mask]\n",
    "            batch_virtual_mask = virtual_mask[batch_mask]\n",
    "            batch_h_protein = h_protein[batch_mask]\n",
    "\n",
    "            valid_clusters = torch.unique(batch_group_indices)\n",
    "            valid_clusters = valid_clusters[valid_clusters != -1]\n",
    "\n",
    "            for cluster in valid_clusters:\n",
    "                cluster_indices = (batch_group_indices == cluster).nonzero(as_tuple=True)[0]\n",
    "                virtual_center_idx = cluster_indices[batch_virtual_mask[cluster_indices]][0]\n",
    "\n",
    "                real_atom_indices = cluster_indices[~batch_virtual_mask[cluster_indices]]\n",
    "                cluster_features_mean = batch_h_protein[real_atom_indices].mean(dim=0)\n",
    "                updated_h_protein[virtual_center_idx] += cluster_features_mean\n",
    "        return updated_h_protein\n",
    "\n",
    "    def aggregate_to_virtual_center_by_batch_optimized(self, h_protein, group_indices, virtual_mask, batch):\n",
    "        # 优化版本函数（需要确保 group_indices >= 0 且从0开始计数）\n",
    "        valid_mask = group_indices != -1\n",
    "        if valid_mask.sum() == 0:\n",
    "            return h_protein.clone()\n",
    "\n",
    "        combined = batch * (group_indices.max()+1) + group_indices\n",
    "        valid_combined = combined[valid_mask]\n",
    "        real_mask = valid_mask & ~virtual_mask\n",
    "\n",
    "        unique_groups, inverse_indices = torch.unique(valid_combined, sorted=True, return_inverse=True)\n",
    "        num_unique_groups = unique_groups.size(0)\n",
    "\n",
    "        real_indices = torch.nonzero(real_mask, as_tuple=False).squeeze(1)\n",
    "        real_combined = combined[real_indices]\n",
    "        real_inverse = torch.searchsorted(unique_groups, real_combined)\n",
    "        real_features = h_protein[real_indices]\n",
    "\n",
    "        sum_features = torch_scatter.scatter_add(real_features, real_inverse, dim=0, dim_size=num_unique_groups)\n",
    "        counts = torch_scatter.scatter_add(torch.ones_like(real_inverse, dtype=torch.float32), real_inverse, dim=0, dim_size=num_unique_groups)\n",
    "        group_mean = sum_features / counts.unsqueeze(1).clamp(min=1.0)\n",
    "\n",
    "        virtual_mask_valid = valid_mask & virtual_mask\n",
    "        if virtual_mask_valid.sum() == 0:\n",
    "            return h_protein.clone()\n",
    "\n",
    "        virtual_indices = torch.nonzero(virtual_mask_valid, as_tuple=False).squeeze(1)\n",
    "        virtual_combined = combined[virtual_indices]\n",
    "        virtual_inverse = torch.searchsorted(unique_groups, virtual_combined)\n",
    "\n",
    "        updated_h_protein = h_protein.clone()\n",
    "        updated_h_protein[virtual_indices] += group_mean[virtual_inverse]\n",
    "\n",
    "        return updated_h_protein\n",
    "\n",
    "\n",
    "# 测试用例\n",
    "if __name__ == \"__main__\":\n",
    "    # 设置随机种子确保可重复性\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    aggregator = ProteinAggregator()\n",
    "\n",
    "    N = 20  \n",
    "    feature_dim = 5\n",
    "    num_batches = 3\n",
    "    h_protein = torch.randn(N, feature_dim)\n",
    "\n",
    "    batch = torch.tensor([0,0,0,0,0,0,1,1,1,1,0,1,2,2,2,2,2,2,2,2])\n",
    "\n",
    "\n",
    "    group_indices = torch.full((N,), -1, dtype=torch.long)\n",
    "\n",
    "\n",
    "    group_indices[0] = 0; group_indices[1] = 0; group_indices[2] = 0  # batch0 cluster0\n",
    "    group_indices[3] = 1; group_indices[4] = 1; group_indices[5] = 1  # batch0 cluster1\n",
    "    group_indices[6] = 0; group_indices[7] = 0; group_indices[8] = 0; group_indices[9] = 0  # batch1 cluster0\n",
    "    # 10,11,12为batch1的虚拟原子，不属于任何簇（-1）\n",
    "    group_indices[13] = 0; group_indices[14] = 0; group_indices[15] = 0  # batch2 cluster0\n",
    "    group_indices[16] = 1; group_indices[17] = 1; group_indices[18] = 1; group_indices[19] = 1 # batch2 cluster1\n",
    "\n",
    "\n",
    "    virtual_mask = torch.zeros(N, dtype=torch.bool)\n",
    "    virtual_mask[2] = True\n",
    "    virtual_mask[5] = True\n",
    "    virtual_mask[9] = True\n",
    "    virtual_mask[15] = True\n",
    "    virtual_mask[19] = True\n",
    "    h_protein[virtual_mask] = 0.0\n",
    "    # 再定义mask_ligand，随便定义几个配体原子（不影响聚合结果）\n",
    "    mask_ligand = torch.zeros(N, dtype=torch.bool)\n",
    "    mask_ligand[10] = True  # 虚拟、配体\n",
    "    mask_ligand[11] = True\n",
    "    mask_ligand[12] = True\n",
    "\n",
    "    # 调用原始版本与优化版本\n",
    "    res_original = aggregator.aggregate_to_virtual_center_by_batch(h_protein, group_indices, virtual_mask, batch)\n",
    "    res_optimized = aggregator.aggregate_to_virtual_center_by_batch_optimized(h_protein, group_indices, virtual_mask, batch)\n",
    "\n",
    "    # 检查结果是否一致\n",
    "    # 使用allclose以允许浮点数上的微小差别\n",
    "    if torch.allclose(res_original, res_optimized, atol=1e-3):\n",
    "        print(\"测试通过：两种实现结果基本一致。\")\n",
    "    else:\n",
    "        print(\"测试失败：两种实现结果存在差异。\")\n",
    "        print(\"原始结果：\", res_original)\n",
    "        print(\"优化结果：\", res_optimized)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molcraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
